\section{CAPS Overview}
%\subsection{Overview}
\label{sec:design:overview}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/arch}
  \caption{Overview of \ac{name} architecture (log auditors and monitors not
  shown). Dotted lines denote the browser and its components, and italic text
denotes new entities or actions in \ac{name}.  As shown in the diagram,
CAPS is currently implemented as a browser plug-in, but we envision it
would become a standard browser component.
  }
  \label{fig:overview}
\end{figure}

\paragraph{Goals}
\ac{name} primarily aims to enable a smooth transition from the Web's existing
\ac{pki} to an \emph{improved \ac{pki}} (which can range from an extension of
the existing \ac{pki} to a new \ac{pki} altogether). We assume that during this
transition, both the existing and improved \acp{pki} will coexist, and that the
improved \ac{pki} will make \ac{mitm} attacks more difficult to carry out.
Hence, \ac{name} must prevent downgrades to the old \ac{pki} as well as \ac{tls}
stripping. More precisely, if a client and server both support the improved
\ac{pki}, then when they perform a handshake, they should negotiate a session
key based on the domain's public key as certified in the improved \ac{pki}. As
secondary objectives, we also seek to prevent domains from becoming inaccessible
due to misconfiguration, private key loss, or private key compromise, and to
minimize the changes to existing interactions between clients, domains, and
\acp{ca}.

\paragraph{Adversary Model}
In designing \ac{name}, we consider a \iac{mitm} adversary. 
%We assume the adversary has access to the
%signing keys for $n$ \acp{ca} and can thus issue and revoke arbitrary
%certificates under these keys. 
We assume that the adversary has full
control of the network during the TLS handshake; that is, the adversary can
intercept, drop, or modify all messages sent among all entities described
below. We assume that the adversary cannot break standard cryptographic primitives.

\paragraph{Architecture}
\autoref{fig:overview} illustrates the \ac{name} architecture and how \ac{name}
achieves the goals stated above. Since \ac{name} transitions from the current
Web \ac{pki}, it necessarily includes the entities in the current \ac{pki}:
\begin{compactitem}
\item \emph{Domains} serve webpages to clients. Each domain has a name such as
  \texttt{example.com}.
\item \emph{\acp{ca}} issue certificates to domains. Each certificate binds a
  set of names to a single public key.
\item \emph{Clients} connect to domains over HTTP or \ac{https}, and in the
  latter case, verify the binding between a domain's name and public key.
\item \emph{Browser/OS vendors} (hereafter simply \emph{vendors}) provide the
  software by which clients connect to domains and verify domains' certificates.
\item \emph{Public logs} maintain a publicly auditable, append-only database of
  certificates, such as those used in \ac{ct}.
\end{compactitem}
\ac{name} introduces a new entity, the \emph{log aggregator}, a
high-availability entity that uses publicly available data to maintain a
database of domains that have deployed \ac{https} and/or the improved \ac{pki}.
As our figure shows, there may be multiple independent log aggregators. While
throughout this section we assume that the log aggregator is separate from other
entities and that there is a globally accepted set of known and trusted log
aggregators, in \autoref{sec:discussion} we discuss how we can relax these
assumptions, namely, by arguing that browser vendors should take on this
responsibility.

% Procedures from the current PKI
As shown in \autoref{fig:overview}, many of the interactions between entities in
the current \ac{pki} remain the same in \ac{name}. \acp{ca} remain entirely unchanged;
they issue certificates
to domains and log newly-issued certificates as they do in the current \ac{pki}
(with \ac{ct}). Clients and domains establish an encrypted communication channel
through the standard \ac{tls} handshake, and vendors provide clients with browser
software.

% Signaling set overview
To prevent an adversary from manipulating an attempted HTTPS connection into
an HTTP connection (and thus bypassing \ac{tls}
completely), the log aggregators use data from public logs to construct a
\emph{signaling set}, which succinctly represents the set of all domains that
support \ac{https}. The log aggregators build this set by downloading the set of
all currently valid (i.e., non-expired) certificates from the logs and
extracting all domains named in these certificates. The log aggregators then
make this set, as well as updates to this set over time, available to client
browsers.  When connecting to a server, the browser first checks whether
the server is in the signaling set; if it is, then the browser will refuse
to engage in an HTTP connection.

% Policy overview
To allow domains more control over their public keys than in the current
\ac{pki}, log aggregators use data from public logs to construct a set of
\emph{\ac{name} policies}, which allows each domain to establish one or more
\emph{authoritative public keys} in the \emph{current} Web \ac{pki}. \ac{name}
policies take a simple and intuitive approach: \emph{treat any public key backed
  by a maximal number of independent certificate chains\footnote{This term means
  that the certificate chains share no public keys except at the leaf.} in the
current \ac{pki} as authoritative}. A domain wanting to increase client
confidence in one of its public keys can obtain additional independent
certificates for that key, and the log aggregators will automatically update
their \ac{name} policies for that domain.

Intuitively, log aggregators simply provide signed pairs of the form
$(\hostname, \policy)$ where \hostname is a domain name and \policy is the
\emph{\ac{name} policy value}, i.e., the number of independent certificate
chains backing an authoritative key for \hostname. In case of a tie, \hostname
may have more than one authoritative key: if public keys $\pk_1$ and $\pk_2$ are
both backed by three independent chains then both public keys are treated as
authoritative for \hostname. To prevent an adversary from downgrading handshakes
in the improved \ac{pki} to a handshake in the existing Web \ac{pki}, each log
aggregator indicates which domains in its signaling set have a \ac{name} policy
value greater than 1.

When establishing an HTTPS connection with a server, clients can use the
signaling set to determine whether a domain has a \ac{name} policy value that is
exactly one or greater than one. In the former case, the client may connect to
the domain using the standard \ac{tls} handshake, but in the latter case, the
client requests policy information from the domain using a \ac{tls} extension
similar to ones currently under consideration for IETF 
standardization~\cite{rfc-extra-cert-1, rfc-extra-cert-2}.
Domains obtain the information from log aggregators and forward it to the
client; if a client receives and verifies a policy of $(\hostname, \policy)$, it
will expect to receive \policy independent certificate chains from the server.
If it receives fewer chains, or if any fail to validate, the client aborts
the connection.

The current PKI actually supports three classes of certificates: standard
domain-validated (DV) certificates, organization-validated (OV) certificates,
and extended validation (EV) certificates. EV certificates require domains to
undergo more rigorous screening than the other two. Hence, the actual \ac{name}
policy value is a pair $(\policy_{EV}, \policy_{!EV})$. For a given domain,
\ac{name} will treat as authoritative a public key with the largest observed
$\policy_{EV}$, with ties broken based on the largest value of $\policy_{!EV}$,
which represents the policy value of all non-EV certificates for the domain.


\section{CAPS Detailed Design}

In this section, we describe \ac{name} in detail, including how it signals which
domains have deployed \ac{https} and improvements to the Web \ac{pki}
(\autoref{sec:design:signaling}), how it provides stronger public-key
authentication over the existing Web \ac{pki} (\autoref{sec:design:policy}), and
how clients establish secure end-to-end connections with servers
(\autoref{sec:design:handshake}). We conclude by describing how \ac{name} thus
enables the bootstrapping of more advanced policies
(\autoref{sec:design:bootstrapping}).

\subsection{Building the Signaling Set}
\label{sec:design:signaling}

The signaling set represents
\begin{inparaenum}
\item a set of \acp{fqdn} (hereafter names) known to have deployed \ac{https}
  (by virtue of having a valid public-key certificate appear in a public log), and
\item the subset of names that have adopted \ac{name} (by
  virtue of having multiple independent certificate chains for the same public
  key).
\end{inparaenum}
Formally, the signaling set is a pair $(\httpsset, \multicertset)$ where
$\httpsset$ and $\multicertset$ are unordered sets of valid names in
ASCII\footnote{A valid name is a Unicode or ASCII string up to 253 bytes in
  length overall, with no label longer than 63 bytes~\cite{rfc1035}. We further
add the requirement that the name has \iac{tld} that is a current global
\ac{tld} according to ICANN. We use ASCII here because we can encode names in
Punycode.} and $\multicertset \subseteq \httpsset$. The set supports a query
operation, formally defined as $\query: \strings \to \{\nohttps, \onecert,
\multicert\}$ where $\strings$ is the set of all ASCII strings and \nohttps,
\onecert, and $\multicert$ are values indicating whether a string is a name
known to have no \ac{https} certificate, a public key backed by one certificate
chain, or a public key backed by multiple independent certificate chains,
respectively.
%Specifically, \query must satisfy \begin{align*} \query(\hostname) = \nohttps
%&\iff \hostname \notin \httpsset \\ \query(\hostname) = \onecert &\iff
%\hostname \in \httpsset \setminus \multicertset \\ \query(\hostname) =
%\multicert &\iff \hostname \in \multicertset \end{align*} for all $\hostname
%\in \strings$.

To build its signaling set, a log aggregator must first determine \httpsset
and \multicertset, which it can achieve using the set of all certificates in the
Web \ac{pki}. The log aggregator maintains a database of current certificates by
using information from public sources, namely,
\begin{inparaenum}
\item public logs that collect Web certificates 
  (e.g., CT and Censys -- see Section~\ref{sec:tracking}),
\item \acp{crl} such as those published by \acp{ca}~\cite{rfc5280} or browser
  vendors~\cite{langley2012revocation, goodwin2015revoking}, and
\item revocation information retrieved from OCSP responders~\cite{rfc6960}.
\end{inparaenum}
The log aggregator updates this database regularly (e.g., each day), thus
maintaining a list of certificates valid on a given day.\footnote{A certificate
  is valid on a given day if the signature on the certificate is valid and if
  that day falls in the certificate's validity period as defined by its
\texttt{notBefore} and \texttt{notAfter} fields~\cite{rfc5280}.}

The log aggregator extracts the names from the currently valid
certificates in its database;
%and converts internationalized domain names to ASCII using the IDNA conversion process~\cite{rfc5891}; 
the resulting set of distinct names is \httpsset. 
The log aggregator also analyzes the certificate chains
in this set to determine \multicertset, a procedure we describe in
\autoref{sec:design:policy}. The log aggregator then creates a representation of
the signaling set and makes it available to client browsers.

Because the signaling set must be available to each client that supports \ac{name},
%and may contain all names in DNS, 
the log aggregator must succinctly represent this set to minimize the bandwidth and storage burdens on
each client. However, simply minimizing the storage burden is insufficient;
clients must store the signaling set in memory to minimize connection latency
overhead. Thus the log aggregator must also represent this set in such a way
that clients can query the set with acceptably small latency and memory.

We considered several approaches when determining how to represent the signaling
set. A Bloom filter~\cite{bloom1970space} supports efficient set membership
queries, but has false positives (which for this application would result in
incorrectly flagging a site as under attack) and for the scale of data we
consider, results in too large a storage burden
(\autoref{sec:evaluation:https}). A filter cascade~\cite{salikhov2014using}
would eliminate false positives, but has the virtually impossible prerequisite
of knowing all names in the DNS namespace, which requires the cooperation of all
\ac{tld} operators (including many national governments). Finally, using an
existing data compression utility (e.g., zpaq) with aggressive compression
parameters could minimize the required storage space, but would also require
decompression and lookup each time a client tried to connect to a site whose
\ac{https} deployment status was not known, resulting in significant latency
overhead (\autoref{sec:evaluation:performance}).
%\steve{Distinguish transmission and local usage overhead}

%\begin{figure}
  %\centering
  %\includegraphics[width=\linewidth]{fig/dafsa}
  %\caption{A simple \ac{dafsa} with one-character transitions, along with the
    %set of strings it represents and its succinct representation as a vector of
    %variable-length bitstrings. In this representation, each edge (gray)
    %consists of a label (blue) and next state (orange), along with flags
  %indicating whether the next state is an accept state (green) and whether the
%edge is the last one outgoing from this state (red).}
  %\label{fig:dafsa}
%\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/dafsa_combined}
  \caption{The first stages of our \ac{dafsa} construction. 
           Each stage modifies the \ac{dafsa} to ultimately minimize the 
           the size of its binary representation.}
  \label{fig:dafsa}
\end{figure}

In our log aggregator prototype, we ultimately chose to represent the signaling
set as a data structure known as a \emph{\acf{dafsa}}, which succinctly stores a
set of strings, supports efficient membership queries in this set, and supports 
efficient, compact construction~\cite{daciuk2000incremental}. As shown
in \autoref{fig:dafsa}, \iac{dafsa} takes advantage of both common prefixes and
suffixes that appear in a set of strings; since such patterns are frequent in a
large set of domain names, much of the redundancy in \httpsset can be removed with this
approach. Additionally, \acp{dafsa} can also be represented succinctly, using an
approach we summarize below~\cite{daciuk2012smaller}. Given the characteristics
of our input set as described in \autoref{sec:evaluation:implementation}, we
make an additional design change, \emph{path compaction},
to our \ac{dafsa} representation that further reduces its size.

\paragraph{Formal \ac{dafsa} Definition}
To precisely describe these changes, we begin by presenting a formal framework
to describe \acp{dafsa}. Formally, \iac{dafsa} is a tuple $(\symbols, \states,
\initstate, \transfunc, \finalstates)$ where
\begin{inparaenum}
\item \symbols is a set of possible \emph{input symbols},
\item \states is a set of \emph{states},
\item \initstate is an \emph{initial state} where $\initstate \in \states$,
\item $\transfunc: \states \times \symbols \to \states$ is a partial function
  called the \emph{state transition function} that maps a state-symbol pair to a
  new state, and
\item \finalstates is a set of \emph{accept states} where $\finalstates
  \subseteq \states$.
\end{inparaenum}
The \ac{dafsa} also has the restriction that the state transition function is
\emph{acyclic}, that is, there is no sequence of states and symbols $(s_1,
\ldots, s_n), (\sigma_1, \ldots, \sigma_n)$ where $\transfunc(s_i, \sigma_i) =
s_{i+1}$ for $1 \le i < n$ and $\transfunc(s_n, \sigma_n) = s_1$.

We represent queries to the signaling set within the \ac{dafsa} as follows: let
\symbols contain a unique symbol \multicertsymbol that is not present in any
name in \httpsset. Then, if there exists a sequence of
states and symbols $(s_0, \ldots, s_n), (\sigma_1, \ldots, \sigma_n)$ that
satisfies
\begin{inparaenum}
\item $\transfunc(s_i, \sigma_{i+1}) = s_{i+1}$ for each $i$ where $0 \le i < n$,
\item $\sigma_1 \| \dots \| \sigma_{n-1} = \hostname$, 
\item $\sigma_n = \multicertsymbol$, and
\item $s_n \in \finalstates$,
\end{inparaenum}
we say that $\query(\hostname) = \multicert$.
Otherwise, if
\begin{inparaenum}
\item $\transfunc(s_i, \sigma_{i+1}) = s_{i+1}$ for each $i$ where $0 \le i < n$,
\item $\sigma_1 \| \dots \| \sigma_{n} = \hostname$, and
\item $s_n \in \finalstates$,
\end{inparaenum}
then $\query(\hostname) = \onecert$. Otherwise, $\query(\hostname) = \nohttps$.

\paragraph{\ac{dafsa} Representation}
We begin by building the \ac{dafsa} as described in previous
work~\cite{daciuk2000incremental} (\autoref{fig:dafsa}). Though this previous work assumes transitions
based on a single character, we consider the possibility of multi-character
symbols and thus our symbol set consists of strings of length up to 253
characters:\footnote{Recall that DNS names can be a maximum of 253 characters.}
$\symbolstrings = \bigcup_{i=0}^{253} \symbols^i$, where \symbols is the set of
all ASCII characters allowed in domain names, and $\symbols^i$ indicates strings
of length $i$.

We succinctly represent this \ac{dafsa} as a bitvector by following the
high-level approach of previous work~\cite{daciuk2012smaller}. Intuitively, we
represent the \ac{dafsa} as a sequence of state encodings, which mostly consist
of outgoing transition encodings. By our definition of \transfunc, for a state
$s$, if $\transfunc(s, \sigma) = t$, then each outgoing transition must be
represented by an encoding of the label $\sigma$ and the destination state $t$.
We observe that in this construction, the overall number of outgoing
transitions, as well as the size of the representation of each transition's
label and destination state, strongly influence the size of the final bitvector.
We thus focus on leveraging patterns in the underlying data to minimize the
overall size of the \ac{dafsa} representation.

\paragraph{Path Compaction}
%\begin{figure}
  %\centering
  %\includegraphics[width=\linewidth]{fig/dafsa_compact}
  %\caption{The \ac{dafsa} from \autoref{fig:dafsa} with its long edges
  %compacted. The binary representation is more succinct than its counterpart.}
  %\label{fig:dafsa_compact}
%\end{figure}
We extend the design of prior work with \emph{path compaction}, which
minimizes the \ac{dafsa} representation by reducing the overall number of
transitions. Intuitively, path compaction removes a connected set of states from
the \ac{dafsa} and replaces transitions into or out of this set with transitions
equivalent to paths through the set. As we formalize below, we can model this
process as the transformation of one \ac{dafsa} into another and use this model
to determine how we should select a set of nodes to ensure a minimal \ac{dafsa}
representation.

Given \iac{dafsa} $(\symbols, \states, \initstate, \transfunc, \finalstates)$,
we define a \emph{path} between $s_1$ and $s_m$ to be a sequence of alternating
states in \states and symbols in \symbols, written $(s_1, \sigma_1, \ldots,
s_m)$, where for all $i$ where $1 \le i < m$, $\transfunc(s_i, \sigma_i)
= s_{i+1}$.
We say that a set of states $\stateset
\subseteq \states$ is a \emph{connected component} if either $\stateset
\subseteq \finalstates$ or $\stateset \cap \finalstates = \emptyset$, and for
any two states $t, u \in \stateset$, 
any path between $t$ and $u$ contains only states in $\stateset$.
The \emph{upstream states} of a connected component \stateset, written
\upstream{\stateset}, is the set of all states $s \in \states \setminus
\stateset$ for which there exists a state $t \in \stateset$ and a symbol
$\sigma$ where $\transfunc(s, \sigma) = t$. The \emph{downstream states} of
\stateset, written \downstream{\stateset}, is the set of all states $s \in
\states \setminus \stateset$ for which there exists a state $t \in \stateset$
and a symbol $\sigma$ where $\transfunc(t, \sigma) = s$. A path \emph{through} a
connected component \stateset is a path $(s_1, \sigma_1, \ldots, s_m)$ where
$s_1 \in \upstream{\stateset}$, for all $i$ where $1 < i < m$, $s_i \in
\stateset$, and $s_m \in \downstream{\stateset}$.

Path compaction consists of repeatedly
\begin{inparaenum}
\item selecting a connected component \stateset within the \ac{dafsa},
\item calculating the estimated reduction in representation size from compacting
  the paths through \stateset, and
\item if the change reduces the size of the \ac{dafsa} representation, removing
  these states from \states and replacing the paths through \stateset with an
  equivalent set of transitions.
\end{inparaenum}
Specifically, when removing \stateset, we transform the \ac{dafsa} $(\symbols,
\states, \initstate, \transfunc, \finalstates)$ to $(\symbols, \states \setminus
\stateset, \initstate, \transfunc', \finalstates)$, where for all paths $(s_1,
\sigma_1, \ldots, s_m)$ through \stateset, $\transfunc'(s_1, \sigma_1 \| \dots \|
\sigma_{m-1}) = s_m$.

Our goal is to select components that result in the greatest reduction in size.
To determine the size reduction of removing a connected component, we must
consider both the reduction in the number of edges in the \ac{dafsa} as well as
any changes to the Shannon entropy of the distributions of symbols and
destination states in the \ac{dafsa}, as removing a component would cause these
distributions to change. To quantify this change, we define several helpful
variables.

For a set $X \subseteq\states$, let \numtrans{X} denote the set of transitions
that start or end in $X$, that is, the number of triples $(s, t, \sigma)$ where
$\transfunc(s, \sigma) = t$ and $s$ or $t$ (or both) is in $X$. For a connected
component $C$, let \numpaths{C} denote the set of paths through $C$. Then the
change in the number of edges by removing $C$ through path compaction is
$|\numpaths{C}| - |\numtrans{C}|$. By collecting the distribution of symbols in
\numtrans{S} and \numtrans{C}, as well as the concatenated symbols in
\numpaths{C} (which we can find via depth-first search from \upstream{C}), we
can compute the change in entropy in symbols and similarly for destination
states, which we write as \symboldh and \destdh, respectively. Suppose that we know the
original entropies \symbolh and \desth, and that we define $\dentropy = \symboldh +
\destdh$ and $\entropy = \symbolh + \desth$. Then we can compute the difference in
size between the two \acp{dafsa} as
\begin{equation}
  |\numtrans{S}| \dentropy + \left(|\numpaths{C}| - |\numtrans{C}|\right)
  (\entropy + \dentropy)
\end{equation}
and only remove $C$ if this quantity is negative.

We found several classes of components that, for our underlying set of domain
names, provided substantial reductions in the size of the \ac{dafsa}
representation. The first was to select what we call \emph{isolated paths}, that
is, paths of the form $(s_1, \sigma_1, \ldots, s_m)$ where for all $i$ such that
$1 < i < m$, $s_i$ only had one incoming and one outgoing transition. Using
techniques from prior work~\cite{daciuk2000incremental} to build the \ac{dafsa}
results in a significant number of isolated paths. Hence performing path
compaction on all such paths results in a size savings of nearly 10\% of the
original \ac{dafsa} size. We also found that selecting a constant $\alpha$ and
then selecting components consisting entirely of states that had one incoming
transition and $\alpha$ outgoing transitions (or vice versa) yielded more modest
but still nontrivial size reductions for $\alpha = 2$ and $\alpha = 3$.

\subsection{Building the \ac{name} Policy Database}
\label{sec:design:policy}

The \ac{name} \emph{policy database} represents a binding between a name and a policy, that
is, the number of independent certificate chains that a client
should expect during a handshake with a server corresponding to the name.
To construct and maintain this database, each log aggregator must keep track of
the certificates and chains active for a domain at any given time. The log
aggregators again rely on the data used to build the signaling set.
%from public sources for this information,
%which includes the data used to build the signaling set, as well as certificate
%chains observed by public logs.

\begin{figure}
  \centering
  \includegraphics[width=0.9\linewidth]{fig/chain}
  \caption{Sample certificate fingerprint graph. $A \rightarrow B$ indicates
    that a certificate with fingerprint $A$ is the authority public key for a
    certificate with fingerprint $B$. Though the leaf certificate
    $\texttt{6ac3c336}\ldots$ has four chains, the bolded fingerprints show that
    only two of the chains are independent.}
  \label{fig:chain}
\end{figure}

A log aggregator uses this data to maintain an internal database with
(many-to-many) maps of
\begin{inparaenum}
\item certificates to names,
\item certificates to public keys, and
\item certificates to chains.
\end{inparaenum}
Regular updates to this database (described in \autoref{sec:design:signaling})
ensure that the log aggregator has a list of currently valid certificates. The
log aggregator can then use the database to construct a mapping of names to
policies. Specifically, the aggregator creates a graph of certificate
fingerprints as shown in \autoref{fig:chain}, and computes the \emph{policy
value}, the minimum number of \ac{ca} public keys that must be compromised for a
\ac{name}-enabled browser to accept a fraudulent certificate for this site. The
policy value can be computed using a straightforward approach (e.g., computing a
minimal vertex separator), allowing the log aggregator to easily construct a
mapping of certificate fingerprints to policy values. The log aggregator can
then perform a series of simple join operations to map each name to the maximum
policy number associated with a certificate containing the name.

The log aggregator constructs this name-to-policy mapping each time it receives
data from public sources (recall from \autoref{sec:design:signaling} that this
occurs at regular, scheduled intervals). Once it has created the mapping, the
log aggregator certifies the name--policy-value pairs in this mapping by
timestamping and signing them. For auditability, the log aggregators
can additionally take an approach similar to that of logs in \ac{ct}, using a
Merkle hash tree to store their policy proofs over time in a cryptographically
verifiable, append-only fashion.

With the policy databases of the log aggregators, a domain can provide the
information necessary for clients to establish the domain's authoritative public
key. The domain periodically downloads the latest \emph{policy proofs}, which
are signed and timestamped name-policy pairs, from each of the log aggregators.
For a name \hostname, a policy value \policy, a timestamp \timestamp, and a log
aggregator \logagg, we specify the policy proof to be
\begin{align}
  %data &= \logagg \concat \hostname \concat \timestamp \concat \policy \\
  \policyproof(\logagg, \hostname, \policy, \timestamp) &= 
  \left\{data, \signature(\pk_{\logagg}^{-1}, data)\right\} \mbox{ where}
  \nonumber \\
  data &= \logagg \concat \pk_{\logagg} \concat \hostname \concat \timestamp \concat \policy
\end{align}
where $\pk_{\logagg}$ and $\pk_{\logagg}^{-1}$ denote respectively the public
and private keys of \logagg, and $\signature(K, m)$ denotes a signature on $m$
with private key $K$. The domain uses these proofs in the handshake described
below.

\subsection{Connection Establishment}
\label{sec:design:handshake}

To establish a connection to a domain, a client (e.g., browser) first queries
the signaling set for the domain's name. If this query returns \onecert then the
client performs a standard TLS handshake (and refuses any attempts to downgrade
to plain HTTP). If the query returns $\multicert$, indicating the domain has
more than one certificate chain, then the client performs the \ac{name}-extended
TLS handshake to establish a connection with the domain. The result of the query
to the signaling set is cached until the next signaling set update, which
eliminates the need for this query in future connections. Caching is
particularly effective at minimizing overhead for operations such as session
resumption~\cite{rfc8446}.

The \ac{name}-extended TLS handshake protocol allows a client to verify a
domain's authoritative public key. The \ac{tls} handshake
protocol~\cite{rfc5246} provides support for open-ended extensions (implemented
in cryptographic libraries), and thus we designed our protocol as an extension
within the existing \ac{tls} handshake.

During the initial
  ClientHello message, the client includes a \ac{name} extension message, which
  consists of a single integer \numlas, indicating the number of policy proofs
  that the domain should send back.
%We assume that a reasonable maximum value for \numlas is enforced; for example,
  %a domain may abort the handshake if \numlas is beyond some acceptable
  %maximum.
In an initial deployment, we expect that typically $k=1$, but allowing the use
of larger values for $k$ provides resilience against compromised log
aggregators.  See Section~\ref{sec:analysis:weaknesses} for further discussion.

The domain then sends back a ServerHello message that contains \numlas recent
policy proofs from \numlas distinct log aggregators, as well as \numlas
certificate chains, which allows the client to verify the domain's policy value
and the certificate chains supporting this value. Formally, suppose a domain has
hostname \hostname and policy value \policy, and selects a set of log
aggregators $\{\logagg_1, \ldots, \logagg_\numlas\}$. Let $\policyproofshort_i =
\policyproof(\logagg_1, \hostname, \policy, \timestamp_i)$ for $1 \le i \le
\numlas$, where $\timestamp_i$ is the timestamp of the policy proof from
$\logagg_i$. Then, the domain sends the following back in the ServerHello
extension message:
\begin{equation}
  \{\policyproofshort_1, \ldots, \policyproofshort_\numlas, \certchain_1,
  \ldots, \certchain_{\policy - 1}\}
\end{equation}
where $\certchain_j$ is a certificate chain for \hostname. In the extension
message, the domain only sends $\policy - 1$ certificate chains because the
remaining chains will be sent in the ServerCertificate message of the TLS
handshake.

The client then checks that
\begin{inparaenum}
\item the signature on each policy proof is valid,
\item the timestamp for each policy proof is sufficiently recent,
\item the name in each policy proof matches the domain name to which 
      the browser is connecting,
\item the policy value for each policy is one more than the number of
  certificate chains sent in the domain's extension message, and
\item each certificate chain is valid as specified in the X.509v3
  standard~\cite{rfc5280}.
\end{inparaenum}
If the above checks pass, the client can then continue with the standard TLS
handshake, which requires the client to verify an additional certificate chain
in the ServerCertificate message and perform all other checks required by the
\ac{tls} handshake protocol.

While our current design uses a custom TLS extension, in the future, \ac{name}
may instead be able to leverage recently proposed TLS
extensions~\cite{rfc-extra-cert-1, rfc-extra-cert-2} designed to allow the
transmission of additional certificates (primarily to facilitate content hosting
by CDNs).  

\subsection{Bootstrapping Advanced Policies}
\label{sec:design:bootstrapping}

Once an authoritative public key for a domain has been established through the
\ac{name} handshake, signatures made by the corresponding private key are useful 
beyond simply improving the domain's security in the current \ac{pki}.
In particular, a signature from the authoritative public key can be
used to verify the binding between a domain and a richer set of policies. For
example, in systems such as ARPKI~\cite{basin2014arpki} and
PoliCert~\cite{szalachowski2014policert}, these policies can specify a set of
\acp{ca} that are authorized to issue certificate for the domain, or even make
the domain a \ac{ca} for itself by pinning specific public keys to the domain.
In this way, the authoritative public key established in \ac{name} can be used
to bootstrap confidence in these advanced policies while preventing downgrades
to the old \ac{pki}.

This bootstrapping approach obviates the need for logs to directly store the
policies, which can be quite large in these previously proposed systems.
Moreover, in \ac{name}, this bootstrapping can take place at any time during
deployment. This means that in the case of a lost private key, a domain can
simply obtain \policy new independent certificate chains, and in the case of a
compromised private key, $\policy + 1$ new independent chains. This contrasts
with previous proposals, which often rely on heavyweight processes that involve
manual \ac{ca} intervention.

