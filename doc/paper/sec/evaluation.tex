\section{Evaluation}
\label{sec:evaluation}

Below, we evaluate \ac{name}' performance.
We first describe the domains represented by the signaling set,
including how we identified these domains. Next, we compare different approaches
and optimizations for representing the signaling set. Finally, we describe the
performance effects of \ac{name} on connection establishment.

\subsection{Signaling Set Domains}
\label{sec:evaluation:https}

Before building a representation of the signaling set, we need to determine
which domains belong in it. Moreover, to determine the long-term
viability of our solution, we also need to understand how the size of this set
of domains may change in the future. Addressing both of these problems requires
a complete and accurate view of the Web \ac{pki}, namely, the set of domains
that are accessible over HTTPS.

We can obtain a view of the Web \ac{pki} using data from public logs (\autoref{sec:design:signaling}). 
Specifically, we obtain public-key
certificates from Censys~\cite{durumeric2015search} and logs in
\ac{ct}~\cite{rfc6962}. From Censys, we collected 1,026 scans of the IPv4
address space over a period ranging from September 12, 2015 to July 3, 2018.
From \ac{ct}, we collected all entries from known \ac{ct} logs that were not
disqualified or unreachable as of July 3,
2018,\footnote{\url{https://www.certificate-transparency.org/known-logs}} which
totaled approximately 1.74B certificates from 26 logs over a period ranging from
March 26, 2013 to July 3, 2018.

%\begin{figure*}
  %\centering
  %\subfloat[Certs.]{
    %\includegraphics[width=0.5\linewidth]{fig/cert_count_valid}
    %\label{fig:count:certs}
  %}
  %\subfloat[Names.]{
    %\includegraphics[width=0.5\linewidth]{fig/name_count_valid}
    %\label{fig:count:names}
  %}
  %\caption{Number of unique certificates and domain names in the Web \ac{pki} as seen by
  %Censys and \ac{ct}.}
  %\label{fig:count}
%\end{figure*}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/cert_count_valid}
  \caption{Number of unique certificates seen by Censys and \ac{ct} over time.}
  \label{fig:count:certs}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/name_count_valid}
  \label{fig:count:names}
  %\caption{Number of unique certificates and domain names in the Web \ac{pki} as seen by
  %Censys and \ac{ct}.}
  \caption{Number of unique names (including hostnames and wildcard names) seen
  by Censys and \ac{ct} over time.}
  \label{fig:count}
\end{figure}

On each of these days, we consider an ``active set'' of certificates consisting
of all certificates that were valid on that day and had an associated
certificate chain rooted in one of the three major root certificate stores,
determined by Apple, Microsoft, or Mozilla. In the Censys dataset, because we
observed a great deal of churn (i.e., certificates disappearing and appearing in
consecutive scans), we considered a certificate as in the active set from the
time it was first observed in our data until its expiration. We then consider
the number of unique, valid domain names, which we use to build the signaling
set.

Figures \autoref{fig:count:certs} and \autoref{fig:count:names} show the number of
domain names observed by Censys, \ac{ct}, and their overlap over time. Our results show that
there are far more certificates (and consequently names and domains) observed by
\ac{ct} than by Censys. It is not clear whether the names seen in \ac{ct} simply
never deployed HTTPS in the wild or whether Censys was not observing certain
certificates.  One likely contributing factor is the increasing prevelance of 
Server Name Indication (SNI), which would cause Censys' probes to be rejected
when they do not include the correct server name.
To resolve these issues into a suitable signaling set, we performed a scan of
port 443 using ZGrab~\cite{durumeric2015search} for all domain names we
extracted from Censys and \ac{ct}, and then we discarded any domain names that
failed to respond. From this method, we isolated a set of 64,050,329 ``valid''
names that we used for testing.

\subsection{Signaling Set Representation}
\label{sec:evaluation:implementation}

As described in \autoref{sec:design:signaling}, our motivation for using \iac{dafsa}-based
representation of the signaling set was twofold: first, the representation has
no false positives or negatives, and second, it can be searched in its
compressed state, leading to a lower memory usage requirement for clients. To
evaluate the effectiveness of these design decisions against other alternatives,
we conducted an experiment to measure the space requirements for the signaling
set in various representations. 
We measured both the fully compressed size 
(which dictates bandwidth usage when transmitting
the set to the client and the client's overhead storing it on disk)
and the size in memory (when being used by the client during certificate verification).

In particular, we compared the plaintext representation of the signaling set (as
of July 3, 2018) with a compressed representation using Bloom filters, the
generic compression utility zpaq,\footnote{While we tested compression with other
  utilities, zpaq had the smallest size. Thus we used zpaq for the experiment to
  compare a near-best-case compression scenario.} and various configurations of
our \ac{dafsa}-based representation. We also compressed the \ac{dafsa}-based
representation using zpaq to find the size of the \ac{dafsa}-based
representation on disk and in transit. 

We specifically tested a Bloom filter with false positive rates of 0.001\%,
0.01\%, and 0.1\%. Since the number of domain names is on the order of
100M~\cite{dnib-14-1}, we expect that the number of false positives will be on
the order of 1k, 10k, and 100k, respectively. We estimate that a false positive
rate of 0.001\% will be sufficient for most users. We tested zpaq using two
compression methods, 1 and 5, where method 1 completes in a short amount of time
(25 seconds) but compresses the input less while method 5 takes a long time (20
minutes) but yields excellent compression. Furthermore, with zpaq method 5, we
tested with 64 MiB and 2048 MiB blocks, where larger blocks typically yield
better compression. Finally, with our \ac{dafsa}-based representation, 
we tested a plain encoding as
well as an encoding using our path-compressed \ac{dafsa}, and compressed each of
these encodings with zpaq method 5 using both block sizes.

\input{table/signaling}

\begin{table}[tbp]
  \centering
  \caption{Size of \ac{name} signaling set on
    July 3, 2018 (\numnames{} names) with various compression approaches. The
    representation size in memory is not shown.}
  \begin{tabular}{|lr|}
    \toprule
    \textbf{Representation} & \textbf{Size (MB)} \\
    \midrule
    Plaintext & \plaintextsize \\
    \midrule
    Bloom Filter (0.001\% FP, best-case) & 192 \\
    Bloom Filter (0.01\% FP, best-case) & \bloomlargesize \\
    Bloom Filter (0.1\% FP, best-case) & \bloommedsize \\
    \midrule
    zpaq (method 1, 16 MiB blocks) & \zpaqlargesize \\
    zpaq (method 5, 64 MiB blocks) & \zpaqmedsize \\
    zpaq (method 5, 2048 MiB blocks) & \zpaqsmallsize \\
    \midrule
    DAFSA & \fsalargesize \\
    DAFSA w/ path compaction (PC) & \fsamedsize \\
    DAFSA w/ zpaq (method 5, 64 MiB blocks) & 184 \\
    DAFSA w/ zpaq (method 5, 2048 MiB blocks) & 145 \\
    DAFSA w/ PC, zpaq (method 5, 64 MiB blocks) & 139 \\
    DAFSA w/ PC, zpaq (method 5, 2048 MiB blocks) & 138 \\
    \bottomrule
  \end{tabular}
  \label{tab:signaling}
\end{table}

The results are shown in \autoref{tab:signaling}. 
Starting from an enormous plaintext corpus of over 1.5 GB,
the various options all achieve impressive compression ratios.
However, the results also indicate that to achieve a competitive size (i.e., 153~MB or less),
Bloom filters would require an unacceptably high false 
positive rate: one in every 10K sites would be falsely signaled
as being under attack and hence would be rendered inaccessible.
%Bloom filters offer high
%compression even with a low false positive rate, and their in-memory
%representation is the same as their on-disk representation. However, they still
%have false positives, which would lead to those domains becoming inaccessible.
While zpaq does not have any false positives or false
negatives and yields excellent compression when run using method 5, 
its in-memory representation of the
signaling set would simply be the uncompressed set of domains, yielding a memory
requirement of 1.5~GB. Our \ac{dafsa}-based representation captures a ``sweet
spot'' between these two alternatives, suffering no false positives or negatives and, in the
best case, an on-disk representation of just 138 MB with an in-memory
representation of 170 MB.

For some clients, an initial download size of 138 MB may be too much. One
approach that such clients can take to protect themselves would be to only track
sites that have more than one certificate, thus reducing disk and memory usage
at the cost of protection against \ac{tls} stripping attacks. To estimate
clients' memory and disk usage in this case, we subsampled the full set of names
and computed the size of the \ac{dafsa} with path compaction (which represents
best-case memory usage in \ac{name}) and the size of the zpaq-compressed
\ac{dafsa} (which represents the best-case disk usage).

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{fig/sample}
  \caption{Size of the signaling set in various representations when 
           the names in the set are subsampled from the full set of names. 
           The labels above each distinct value on the $x$-axis
           denotes the fraction of the full set that was sampled.}
  \label{fig:sample}
\end{figure}

\autoref{fig:sample} shows the results of this experiment. If the fraction of
domains that use multiple independent certificate chains for the same name is
small, as we would anticipate, then clients who opt for this approach can
significantly reduce their memory and disk usage in \ac{name}. 
For example, even if 10\% of all HTTPS websites deployed additional certificates,
the compressed DAFSA representation would require less than 30~MB.
Of course, at very low levels of adoption,
the advantage of the \ac{dafsa}-based
approach over a list of names decreases. This makes sense, given that the
\ac{dafsa} is designed to take advantage of common substrings (especially
prefixes and suffixes) in a set.

\subsection{Signaling Set Updates}
\label{sec:evaluation:updates}

%\begin{figure*}[t]
  %\centering
  %\subfloat[Size of different representations of added names over time.]{
    %\includegraphics[width=0.5\linewidth]{fig/added_name_set_size}
    %\label{fig:updates:added}
  %}
  %\subfloat[Size of different representations of deleted names over time.]{
    %\includegraphics[width=0.5\linewidth]{fig/deleted_name_set_size}
    %\label{fig:updates:deleted}
  %}
  %\caption{Size of update sets over time.}
  %\label{fig:updates}
%\end{figure*}

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{fig/added_name_set_size}
  \caption{Size of added name sets over time.}
  \label{fig:updates:added}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{fig/deleted_name_set_size}
  \label{fig:updates:deleted}
  \caption{Size of deleted names sets over time.}
  \label{fig:updates}
\end{figure}

Because the signaling set will be updated over time, we also carried out an
experiment to determine the size of updates that will be sent to clients. 
An update to the signaling set consists of a set of names that have been added to the signaling
set since the most recent version, as well as a set of names that have been
deleted due to certificate expiration or revocation. We computed the set of
added and deleted names for our range of scans, aggregating these sets by week.
We then computed the sizes of these sets in four different representations:
\begin{inparaenum}[(1)]
\item as an uncompressed text file of name strings,
\item as a compressed zpaq archive containing the above file,
\item as \iac{dafsa} of the set of strings, and
\item as a compressed zpaq archive containing the above \ac{dafsa}.
\end{inparaenum}
For each method, we used the variant that produced the smallest representation;
for example, we used the zpaq method that produced the smallest archive (method
5 with 64 MiB blocks) and our \ac{dafsa} representation used path compaction.
We experimented with the full set of names.

\autoref{fig:updates} shows the results of our experiment. As
\autoref{fig:count} would indicate, the size of the signaling set has increased
over time, and thus the set of added names is consistently larger than the set
of deleted names. Given the relatively modest sizes of these sets compared to
that of the full signaling set, the most space-efficient method for representing
and transmitting these updates to clients is actually a zpaq-compressed archive
of the raw text file of names rather than \iac{dafsa}-based representation. From
a technical perspective, this method of transmission is also advantageous:
clients can simply add the set of added names to their existing \ac{dafsa}, and
build (and subsequently add to) a new \ac{dafsa} for the set of deleted names.
Our results show that updates (added and deleted names) are typically between 2
and 3~MB per week or $\sim$293-439~KB/day; by comparison, downloading the Google
homepage requires approximately 400~KB.

% BP: Why release once a week instead of every day?
%Releasing signaling set updates each week means that some false positives and
%false negatives are possible in \ac{name}, albeit under limited circumstances.
%Specifically, false positives (which render a domain inaccessible) are possible
%for up to a week, but only if a domain chooses to no longer serve its site over
%\ac{https}, lets its certificates expire, and does not inform the log
%aggregators in advance. False negatives (which enable \ac{tls} stripping
%attacks) are possible for up to a week, but only if a domain newly deploys
%\ac{https} by having a certificate issued and then immediately begins serving
%its site. Thus, not only are these pitfalls unlikely in practice, with advance
%planning and minimal effort, domains can avoid both of these situations.

\subsection{Connection Establishment}
\label{sec:evaluation:performance}

%\begin{figure*}[thb]
  %\centering
  %\subfloat[Proof count]{
    %\includegraphics[width=0.5\linewidth]{fig/eval_tls_ext/0-time_elapsed_vs_num_proofs_requested}
    %\label{fig:evaltlsext:numproof}
  %}
  %\subfloat[Chain count]{
    %\includegraphics[width=0.5\linewidth]{fig/eval_tls_ext/1-time_elapsed_vs_num_chains_sent}
    %\label{fig:evaltlsext:numchain}
  %}
  %\quad
  %\subfloat[Chain length]{
    %\includegraphics[width=0.5\linewidth]{fig/eval_tls_ext/2-time_elapsed_vs_num_certs_per_chain}
    %\label{fig:evaltlsext:numcert}
  %}
  %\subfloat[Chain size]{
    %\includegraphics[width=0.5\linewidth]{fig/eval_tls_ext/3-time_elapsed_vs_avg_chain_size}
    %\label{fig:evaltlsext:sizechain}
  %}
  %\caption{Handshake latency in different scenarios. Error bars represent
  %standard error.}
  %\label{fig:evaltlsext}
%\end{figure*}

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{fig/eval_tls_ext/0-time_elapsed_vs_num_proofs_requested}
  \caption{Handshake latency with different numbers of proofs requested. Error
  bars represent standard error.}
  \label{fig:evaltlsext:numproof}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{fig/eval_tls_ext/1-time_elapsed_vs_num_chains_sent}
  \caption{Handshake latency with different numbers of certificate chains sent
  from the server. Error bars represent standard error.}
  \label{fig:evaltlsext:numchain}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{fig/eval_tls_ext/2-time_elapsed_vs_num_certs_per_chain}
  \caption{Handshake latency with different average certificate chain length (in
  certificates). Error bars represent standard error.}
  \label{fig:evaltlsext:numcert}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{fig/eval_tls_ext/3-time_elapsed_vs_avg_chain_size}
  \label{fig:evaltlsext:sizechain}
  \caption{Handshake latency with different average certificate chain size (in
  bytes). Error bars represent standard error.}
  \label{fig:evaltlsext}
\end{figure}

To measure the performance of connection establishment in \ac{name}, we
implemented the handshake as a custom \ac{tls} extension in the OpenSSL library.
For concrete evaluation of this extension, we use nginx and curl with minor
modifications to use our \ac{tls} extension.

Additionally, we constructed sample sets of domain names based on four parameters:
\begin{inparaenum}
\item the number of proofs requested by the client during the
  ClientHello message (\numlas),
\item the number of certificate chains the domain sends during the ServerHello
  message (\policy),
\item the average number of certificates per chain, and
\item the average size of each certificate chain.
\end{inparaenum}
While varying each of these parameters, we measured the amount of extra data
sent in the \ac{name} handshake, and the latency of the handshake both with and
without the \ac{name} \ac{tls} extension.

We tested this both over the Internet (by connecting to a virtual private server
with latency varying from 30 to 300 ms, referred to as \emph{WAN}), as well
as over the local loopback interface (referred to as \emph{localhost}). The
tests over the internet to \emph{WAN} provide an indication of the effect of
the extension on ``real world'' servers, which are usually accessed over WAN,
whereas the \emph{localhost} tests provide a lower bound on time added due to
sending/receiving/processing extra data. A total of 15385 TLS connections were
established for our testing: 5768 over WAN, 9617 over localhost.

Our results, shown in Figures~\ref{fig:evaltlsext:numproof},
\ref{fig:evaltlsext:numchain}, \ref{fig:evaltlsext:numcert}, and
\ref{fig:evaltlsext:sizechain}, show that in comparison to the mean time
elapsed, there is an approximately 5\% increase in connection establishment
time: an average of 11ms longer for WAN and 1.2ms for localhost. However,
since our \ac{tls} extension does not add any extra round-trips to the
handshake, the time added is small, especially in comparison to random
measurement fluctuations (e.g., when we look at confidence intervals within one
standard deviation from the mean --- shown as error bars in the figures).

The extra data sent in the \ac{name} handshake is directly dependent on the size
and number of certificate chains, as well as the number of proofs sent. In
particular, the extra data sent from client to server is 1 byte, and the extra
data sent from server to client is
$(2 + (292 \times \text{\#proofs}) +
(\sum_{\text{chain}}\texttt{sizeof}(\text{chain})))$ bytes. 
%While this means
%that some connections may result in a great deal of extra data sent, we can
%expect that the vast majority of domains will not send additional certificate
%chains and the overhead will remain small.
