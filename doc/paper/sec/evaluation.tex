\section{Evaluation}
\label{sec:evaluation}

Below, we evaluate the performance of \ac{name} in our prototype.
%We first describe the domains represented by the signaling set,
%including how we identified these domains. Next, we compare different approaches
%and optimizations for representing the signaling set. Finally, we describe the
%performance effects of \ac{name} on connection establishment.

\subsection{Signaling Set Domains}
\label{sec:evaluation:https}

%Before building a representation of the signaling set, we need to determine
%which domains belong in it. Moreover, to determine the long-term viability of
%our solution, we also need to understand how the size of this set of domains may
%change in the future. Addressing both of these problems requires a complete and
%accurate view of the Web \ac{pki}, namely, the set of domains accessible over
%HTTPS.

We can obtain a view of the Web \ac{pki} using data from public logs (\autoref{sec:design:signaling}). 
Specifically, we obtain public-key
certificates from Censys~\cite{durumeric2015search} and logs in
\ac{ct}~\cite{rfc6962}. From Censys, we collected 1,026 scans of the IPv4
address space from September 12, 2015 to July 3, 2018.
From \ac{ct}, we collected all entries from known \ac{ct} logs that were not
disqualified or unreachable as of July 3,
2018,\footnote{\url{https://www.certificate-transparency.org/known-logs}} which
totaled approximately 1.74B certificates from 26 logs from
March 26, 2013 to July 3, 2018.

%\begin{figure*}
  %\centering
  %\subfloat[Certs.]{
    %\includegraphics[width=0.5\linewidth]{fig/cert_count_valid}
    %\label{fig:count:certs}
  %}
  %\subfloat[Names.]{
    %\includegraphics[width=0.5\linewidth]{fig/name_count_valid}
    %\label{fig:count:names}
  %}
  %\caption{Number of unique certificates and domain names in the Web \ac{pki} as seen by
  %Censys and \ac{ct}.}
  %\label{fig:count}
%\end{figure*}

\begin{figure}
  \centering
  \includegraphics[width=0.8\linewidth]{fig/name_count_valid}
  %\caption{Number of unique certificates and domain names in the Web \ac{pki} as seen by
  %Censys and \ac{ct}.}
  \vspace{-2mm}
  \caption{Number of unique names (including hostnames and wildcard names) seen
  by Censys and \ac{ct} over time.}
  %\label{fig:count}
  \vspace{-5mm}
  \label{fig:count:names}
\end{figure}

On each of these days, we consider an ``active set'' of certificates consisting
of all certificates that were valid on that day and had an associated
certificate chain rooted in one of the three major root certificate stores,
determined by Apple, Microsoft, or Mozilla. In the Censys dataset, because we
observed a great deal of churn (i.e., certificates disappearing and appearing in
consecutive scans), we included a certificate in the active set from the time it
was first observed in our data until its expiration. We then consider the number
of unique, valid domain names to build the signaling set.

\autoref{fig:count:names} shows the number of domain names observed by Censys,
\ac{ct}, and both over time. We found that \ac{ct} observes vastly more
certificates (and consequently names) than Censys. It is unclear what causes
this large discrepancy. One possibility is that many certificates are simply
never deployed in public-facing HTTPS sites. Another likely contributing factor
is the increasing use of Server Name Indication (SNI)~\cite{rfc6066}, which
cause Censys' probes to be rejected when they do not include the correct server
name.

From Censys and \ac{ct}, we obtained a total of 156,289,973 valid domain names
for which a certificate had been issued. To address the possibility that many of
these names may not be used for public-facing sites, we performed a scan of port
443 (the default for \ac{https}) using ZGrab~\cite{durumeric2015search} for all
of these domain names, and discarded any domain names that consistently failed
to respond. This resulted in 64,050,329 names that we used for testing, as
described below.

\subsection{Signaling Set Representation}
\label{sec:evaluation:implementation}

As described in \autoref{sec:design:signaling}, our motivation for using
\iac{dafsa}-based representation of the signaling set was twofold: first, the
representation has no false positives or negatives, and second, it can be
searched in its compressed state, reducing client memory usage. 
To evaluate the effectiveness of these design decisions, we
measured the space requirements for the signaling set
in various representations. We measured both the fully compressed size (used
when transmitting the set to the client and when stored on disk) and the size in
memory (when being used during certificate verification).

In particular, we compared the plaintext representation of the signaling set (as
of July 3, 2018) with a compressed representation using Bloom filters, the
generic compression utility zpaq~\cite{zpaq},\footnote{While we tested
  compression with other utilities, zpaq had the smallest size.} and
various configurations of our \ac{dafsa}-based representation. We also
compressed the \ac{dafsa}-based representation using zpaq to find its size on
disk and in transit. 

We specifically tested a Bloom filter with false positive rates of 0.001\%,
0.01\%, and 0.1\%. Since the number of domain names is on the order of
100M~\cite{dnib-14-1}, we expect that the number of false positives will be on
the order of 1k, 10k, and 100k, respectively. We estimate that a false positive
rate of 0.001\% will be sufficient for most users. We tested zpaq using two
compression methods, 1 and 5, where method 1 completes in a short amount of time
(25 seconds) but compresses the input less while method 5 takes a long time (20
minutes) but yields excellent compression. Furthermore, with zpaq method 5, we
tested with 64 MiB and 2048 MiB blocks, where larger blocks typically yield
better compression. Finally, with our \ac{dafsa}-based representation, we tested
a plain encoding as well as an encoding using our path-compressed \ac{dafsa},
and compressed each of these encodings with zpaq method 5 using both block
sizes.

\input{table/signaling}

\begin{table}[tbp]
  \small
  \centering
  \caption{Size (on-disk or in transit) of \ac{name} signaling set on
    July 3, 2018 (\numnames{} names) with various compression approaches. The
    representation size in memory is not shown.}
  \vspace{-2mm}
  \begin{tabular}{|lr|}
    \toprule
    \textbf{Representation} & \textbf{Size (MB)} \\
    \midrule
    Plaintext & \plaintextsize \\
    \midrule
    Bloom Filter (0.001\% FP, best-case) & 192 \\
    Bloom Filter (0.01\% FP, best-case) & \bloomlargesize \\
    Bloom Filter (0.1\% FP, best-case) & \bloommedsize \\
    \midrule
    zpaq (method 1, 16 MiB blocks) & \zpaqlargesize \\
    zpaq (method 5, 64 MiB blocks) & \zpaqmedsize \\
    zpaq (method 5, 2048 MiB blocks) & \zpaqsmallsize \\
    \midrule
    DAFSA & \fsalargesize \\
    DAFSA w/ path compaction (PC) & \fsamedsize \\
    DAFSA w/ zpaq (method 5, 64 MiB blocks) & \fsazpaqlargesize \\
    DAFSA w/ zpaq (method 5, 2048 MiB blocks) & \fsazpaqmedsize \\
    DAFSA w/ PC, zpaq (method 5, 64 MiB blocks) & \fsapczpaqlargesize \\
    DAFSA w/ PC, zpaq (method 5, 2048 MiB blocks) & \fsapczpaqmedsize \\
    \bottomrule
  \end{tabular}
  \vspace{-4mm}
  \label{tab:signaling}
\end{table}

The results are shown in \autoref{tab:signaling}. Starting from a plaintext
corpus of over 1.5 GB, the various options all achieve impressive compression
ratios. However, the results also indicate that to achieve a competitive size
(i.e., \bloomlargesize{}~MB or less), Bloom filters require an
unacceptably high false positive rate: one in every 10K sites would be falsely
signaled as supporting \ac{https} and hence would be rendered inaccessible.
While zpaq does not have any false positives or false negatives and yields
excellent compression when run using method 5, its in-memory representation is
simply the uncompressed set of domains, yielding a memory requirement of 1.5~GB.
Our \ac{dafsa}-based representation captures a ``sweet spot'' between these two
alternatives, suffering no false positives or negatives and, in the best case,
an on-disk representation of just \fsapczpaqmedsize{}~MB with an in-memory
representation of \fsamedsize{}~MB.

%For comparison, the set of all names from Censys and \ac{ct} (including
%unresponsive names) totaled 3.48~GB, and using our signaling set
%representation, achieved sizes of 409~MB in memory (using path compaction) and
%335~MB on disk and in transit (using path compaction and zpaq method 5 with
%2048~MiB blocks). Thus the set of responsive names we used for testing comprised
%41.6\% of all observed valid names, 43.4\% of the total uncompressed size of
%all names from Censys and \ac{ct}, 46.5\% of the size in memory with our
%\ac{dafsa} representation, and 44.2\% of the size on disk and in transit.

For some clients, an initial download size of \fsapczpaqmedsize{}~MB may be too
much. One approach that such clients might take to protect themselves would be
to only track sites that have more than one certificate (i.e., sites with
$\policy > 1$). This would ensure that such clients still benefit from greater
resiliency against CA compromises, particularly for ``high-value'' domains that
take the effort to obtain extra certificates. For these clients, this
optimization would reduce disk and memory usage, but \ac{name} would
no longer protect such clients from \ac{tls} stripping attacks targeting
``normal'' domains (those with a single certificate). To estimate clients'
memory and disk usage in this case, we subsampled the full set of names and
computed the size of the \ac{dafsa} with path compaction 
%(which represents best-case memory usage in \ac{name}) 
and the size of the zpaq-compressed
\ac{dafsa} (which represents the best-case disk usage).

\begin{table}[tbp]
  \centering
  \small
  \caption{Size of the signaling set in various representations when the names
  are subsampled from the full set of names.}
  \vspace{-2mm}
  \begin{tabular}{|lccccc|}
    \toprule
    %\textbf{Fraction} & \textbf{Names} & \textbf{Uncompressed (MB)} &
    %\textbf{\ac{dafsa} (MB)} & \textbf{Compressed \ac{dafsa} (MB)}\\
    \textbf{Fraction} & \textbf{0.01} & \textbf{0.05} & \textbf{0.1} &
    \textbf{0.2} & \textbf{0.5} \\
    \midrule
    \textbf{Names (100K)} & 6.39 & 32.0 & 64.1 & 128 & 320 \\
    \midrule
    \textbf{Uncompressed (MB)} & 15.1 & 75.5 & 151 & 302 & 755 \\
    \textbf{\ac{dafsa} (MB)} & 5.25 & 22.9 & 41.7 & 73.1 & 140 \\
    \textbf{Compressed \ac{dafsa} (MB)} & 4.21 & 18.2 & 33.0 & 58.1 & 112 \\
    \bottomrule
  \end{tabular}
  \vspace{-4mm}
  \label{tab:sample}
\end{table}

\autoref{tab:sample} shows the results. If the fraction of domains that use
multiple independent certificate chains for the same name is small, as we would
anticipate, then \ac{name} clients significantly reduce their memory and disk
usage. For example, even if 10\% of all HTTPS websites deployed additional
certificates, the compressed DAFSA representation would require just 33~MB. Of
course, at very low levels of adoption, the advantage of the \ac{dafsa}-based
approach over a list of names decreases. This makes sense, given that the
\ac{dafsa} takes advantage of common substrings.
%(especially prefixes and suffixes) in a set.

\subsection{Signaling Set and Certificate Updates}
\label{sec:evaluation:updates}

%\begin{figure*}[t]
  %\centering
  %\subfloat[Size of different representations of added names over time.]{
    %\includegraphics[width=0.5\linewidth]{fig/added_name_set_size}
    %\label{fig:updates:added}
  %}
  %\subfloat[Size of different representations of deleted names over time.]{
    %\includegraphics[width=0.5\linewidth]{fig/deleted_name_set_size}
    %\label{fig:updates:deleted}
  %}
  %\caption{Size of update sets over time.}
  %\label{fig:updates}
%\end{figure*}

\begin{figure}[t]
  \centering
  %\vspace{-2mm}
  \includegraphics[width=0.95\linewidth]{fig/combined_update_size}
  \vspace{-2mm}
  \caption{Size of update set (added name set and deleted name set) in different
  formats over time.}
  \vspace{-5mm}
  \label{fig:updates}
\end{figure}

Because the signaling set will be updated over time, we 
experimented to determine the size of updates sent to clients. An
update to the signaling set consists of the names added to the signaling set
since the most recent version, as well the names deleted due to certificate
expiration or revocation. We computed the set of added and deleted names for our
range of scans, aggregating these sets by week. We then computed the combined
sizes of these sets in four different representations:
\begin{inparaenum}[(1)]
\item as an uncompressed text file of name strings,
\item as a compressed zpaq archive containing the above file,
\item as \iac{dafsa} of the set of strings, and
\item as a compressed zpaq archive containing the above \ac{dafsa}.
\end{inparaenum}
For each method, we used the variant that produced the smallest representation;
e.g., we used the zpaq method that produced the smallest archive (method
5 with 64 MiB blocks) and our \ac{dafsa} representation used path compaction.
We experimented with the full set of names.

\autoref{fig:updates} shows the results. The size of added and deleted names is
slowly increasing over time, with the set of added names consistently being
larger than the set of deleted names (Appendix \steve{TODO}). Given the
relatively modest sizes of these sets compared to the full signaling
set, the most space-efficient method for representing and transmitting these
updates to clients is a zpaq-compressed archive of the raw text file of names
rather than \iac{dafsa}-based representation. This method of transmission is
also advantageous since clients can simply add the set of added names to their
existing \ac{dafsa}, then build (and subsequently add to) a new \ac{dafsa} for
the set of deleted names. Our results show that updates are typically less than
3~MB per week or $\sim$439~KB/day; by comparison, downloading the Google
homepage requires approximately 400~KB.

Under certain circumstances, changes in a domain's \ac{ca} may cause an
incorrect policy value update. Specifically, if a domain obtains a new
independent certificate chain (e.g., by switching \acp{ca}) for the same public
key without revoking the old one, log aggregators may report a policy value one
higher than the domain has, potentially affecting the signaling set and
\ac{name} handshakes. We reviewed our database for these potential cases and
found this affected only 0.11\% of the overall set. This
%72,034 names in our test set of names, or 
is a conservative upper bound, containing certificates that are almost certainly
from the same issuer with slightly different issuer organization names, such as
``Gandi'' and ``GANDI SAS'', indicating that these failures are likely to be
almost nonexistent in practice.

% BP: Why release once a week instead of every day?
%Releasing signaling set updates each week means that some false positives and
%false negatives are possible in \ac{name}, albeit under limited circumstances.
%Specifically, false positives (which render a domain inaccessible) are possible
%for up to a week, but only if a domain chooses to no longer serve its site over
%\ac{https}, lets its certificates expire, and does not inform the log
%aggregators in advance. False negatives (which enable \ac{tls} stripping
%attacks) are possible for up to a week, but only if a domain newly deploys
%\ac{https} by having a certificate issued and then immediately begins serving
%its site. Thus, not only are these pitfalls unlikely in practice, with advance
%planning and minimal effort, domains can avoid both of these situations.

% Put the figures here to make them display on a single page.
%\begin{figure}[t]
  %\centering
  %\includegraphics[width=\linewidth]{fig/eval_tls_ext/0-time_elapsed_vs_num_proofs_requested}
  %\caption{Handshake latency with different numbers of proofs requested. Error
  %bars represent standard error.}
  %\label{fig:evaltlsext:numproof}
%\end{figure}

%\begin{figure}[t]
  %\centering
  %\includegraphics[width=\linewidth]{fig/eval_tls_ext/1-time_elapsed_vs_num_chains_sent}
  %\caption{Handshake latency with different numbers of certificate chains sent
  %from the server. Error bars represent standard error.}
  %\label{fig:evaltlsext:numchain}
%\end{figure}

%\begin{figure}[t]
  %\centering
  %\includegraphics[width=\linewidth]{fig/eval_tls_ext/2-time_elapsed_vs_num_certs_per_chain}
  %\caption{Handshake latency with different average certificate chain length (in
  %certificates). Error bars represent standard error.}
  %\label{fig:evaltlsext:numcert}
%\end{figure}

%\begin{figure}[t]
  %\centering
  %\includegraphics[width=\linewidth]{fig/eval_tls_ext/3-time_elapsed_vs_avg_chain_size}
  %\caption{Handshake latency with different average certificate chain size (in
  %bytes). Error bars represent standard error.}
  %\label{fig:evaltlsext:sizechain}
%\end{figure}

\subsection{Connection Establishment}
\label{sec:evaluation:performance}

%\begin{figure*}[thb]
  %\centering
  %\subfloat[Proof count]{
    %\includegraphics[width=0.5\linewidth]{fig/eval_tls_ext/0-time_elapsed_vs_num_proofs_requested}
    %\label{fig:evaltlsext:numproof}
  %}
  %\subfloat[Chain count]{
    %\includegraphics[width=0.5\linewidth]{fig/eval_tls_ext/1-time_elapsed_vs_num_chains_sent}
    %\label{fig:evaltlsext:numchain}
  %}
  %\caption{Handshake latency in different scenarios. Error bars represent
  %standard error.}
  %\label{fig:evaltlsext}
%\end{figure*}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\linewidth]{fig/eval_tls_ext/1-time_elapsed_vs_num_chains_sent}
  \vspace{-3mm}
  \caption{Handshake latency vs.\@ the number of certificate chains sent by the
  domain. Error bars are standard error.}
  \label{fig:numchain}
  \vspace{-4mm}
\end{figure}

To measure the performance of connection establishment in \ac{name}, we
implemented the handshake as a custom \ac{tls} extension in the OpenSSL library.
For concrete evaluation of this extension, we use \texttt{nginx} and \texttt{curl} with minor
modifications to use our \ac{tls} extension.

Additionally, we constructed sample sets of domain names based on four parameters:
\begin{inparaenum}
\item the number of proofs requested during the ClientHello message (\numlas),
\item the number of certificate chains sent with the ServerHello
  message (\policy),
\item the average number of certificates per chain, and
\item the average size of each certificate chain.
\end{inparaenum}
While varying each of these parameters, we measured the amount of extra data
sent in the \ac{name} handshake, and the latency of the handshake both with and
without the \ac{name} \ac{tls} extension.

We tested this both over the Internet (by connecting to a virtual private server
with latency varying from 30 to 300 ms), as well as over the local loopback
interface. The tests over the internet (\emph{WAN}) provide an indication of the
effect of the extension on ``real world'' servers, whereas the \emph{localhost}
tests provide a lower bound on time added due to sending/receiving/processing
extra data. A total of 15385 TLS connections were established for our testing:
5768 over WAN, 9617 over localhost.

Our results were similar in each case, with a representative example shown in
\autoref{fig:numchain} (others in Appendix \steve{TODO}). In comparison to the
mean time elapsed, there is an approximately 5\% increase in connection
establishment time: an average of 11ms longer for WAN and 1.2ms for localhost.
Since our \ac{tls} extension does not add any extra round-trips to the
handshake, the time added is small compared to random
measurement fluctuations (i.e., the error bars).

%While this means
%that some connections may result in a great deal of extra data sent, we can
%expect that the vast majority of domains will not send additional certificate
%chains and the overhead will remain small.
