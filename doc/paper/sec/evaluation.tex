\section{Evaluation}
\label{sec:evaluation}

In this section, we describe our evaluation of the performance and overhead of
\ac{name}. We first describe the domains represented by the signaling set,
including how we determined these domains. Next, we compare different approaches
and optimizations for representing the signaling set. Finally, we describe the
performance effects of \ac{name} on connection establishment.

\subsection{Signaling Set Domains}
\label{sec:evaluation:https}

Before building a representation of the signaling set, we need to determine
which domains belong in the signaling set. Moreover, to determine the long-term
viability of our solution, we also need to understand how the size of this set
of domains may change in the future. Addressing both of these problems requires
a complete and accurate view of the Web \ac{pki}, namely, the set of domains
that are accessible over HTTPS.

We can obtain a view of the Web \ac{pki} using data from public logs, as we
describe in \autoref{sec:design}. Specifically, we can obtain public-key
certificates from sources such as Censys~\cite{durumeric2015search} and logs in
\ac{ct}~\cite{rfc6962}. From Censys, we collected 1,026 scans of the IPv4
address space over a period ranging from September 12, 2015 to July 3, 2018.
From \ac{ct}, we collected all entries from known \ac{ct} logs that were not
disqualified or unreachable as of July 3,
2018,\endnote{\url{https://www.certificate-transparency.org/known-logs}} which
totaled approximately 1.74B certificates from 26 logs over a period ranging from
March 26, 2013 to July 3, 2018.

\begin{figure*}
  \centering
  \subfloat[Certs.]{
    \includegraphics[width=0.33\linewidth]{fig/cert_count_valid}
    \label{fig:count:certs}
  }
  \subfloat[Names.]{
    \includegraphics[width=0.33\linewidth]{fig/name_count_valid}
    \label{fig:count:names}
  }
  \subfloat[Domains.]{
    \includegraphics[width=0.33\linewidth]{fig/name_count_valid}
    \label{fig:count:domains}
  }
  \caption{Certificates, names, and domains in the Web \ac{pki} as seen by
  Censys and \ac{ct}. \steve{The domains graphic is a placeholder for now.}}
  \label{fig:count}
\end{figure*}

On each of these days, we consider an ``active set'' of certificates consisting
of all certificates that were valid on that day and had an associated
certificate chain rooted in one of the three major root certificate stores,
determined by Apple, Microsoft, or Mozilla. In the Censys dataset, because we
observed a great deal of churn (i.e., certificates disappearing and appearing in
consecutive scans), we considered a certificate as in the active set from the
time it was first observed in our data until its expiration. We then consider
the number of unique, valid domain names, which we use to build the signaling
set.

\autoref{fig:count:certs} and \autoref{fig:count:names} shows the number of each
observed by Censys, \ac{ct}, and their overlap over time. Our results show that
there are far more certificates (and consequently names and domains) observed by
\ac{ct} than by Censys. It is not clear whether the names seen in \ac{ct} simply
never deployed HTTPS in the wild or whether Censys was not observing certain
certificates. However, to build a suitable signaling set, we performed a scan of
port 443 using ZGrab~\cite{durumeric2015search} for all domain names we
encountered and discarded any domain names that no longer respond. From this
method, we isolated a set of 64,050,329 ``valid'' names that we used for testing.

\subsection{Signaling Set Representation}
\label{sec:evaluation:implementation}

As described in \autoref{sec:design}, my motivation for using \iac{dafsa}-based
representation of the signaling set was twofold: first, the representation has
no false positives or negatives, and second, it can be searched in its
compressed state, leading to a lower memory usage requirement for clients. To
evaluate the effectiveness of these design decisions against other alternatives,
we conducted an experiment to measure the space requirements for the signaling
set in various representations, both on disk (when transmitted to the client)
and in memory (when being used by the client during certificate verification).

In particular, we compared the plaintext representation of the signaling set (as
of July 3, 2018) with a compressed representation using Bloom filters, the
compression utility zpaq,\footnote{While we tested compression with other
  utilities, zpaq had the smallest size. Thus we used zpaq for the experiment to
  compare a near-best-case compression scenario.} and various configurations of
my \ac{dafsa}-based representation. we also compressed the \ac{dafsa}-based
representation using zpaq to find the size of the \ac{dafsa}-based
representation on disk (as it would be used uncompressed in memory).

We specifically tested a Bloom filter with false positive rates of 0.001\%,
0.01\%, and 0.1\%. Since the number of domain names is on the order of
100M~\cite{dnib-14-1}, we expect that the number of false positives will be on
the order of 1k, 10k, and 100k, respectively. we estimate that a false positive
rate of 0.001\% will be sufficient for most users. we tested zpaq using two
compression methods, 1 and 5, where method 1 completes in a short amount of time
(25 seconds) but compresses the input less while method 5 takes a long time (20
minutes) but yields excellent compression. Furthermore, with zpaq method 5, we
tested with 64 MiB and 2048 MiB blocks, where larger blocks typically yield
better compression. Finally, with my \ac{dafsa}-based representation, which
extends previous work~\cite{daciuk2012smaller}, we tested a plain encoding as
well as an encoding of a path-compressed \ac{dafsa}, and compressed each of
these encodings with zpaq method 5 using both block sizes.

\input{table/signaling}

\begin{table}[t]
  \centering
  \caption{Size of \ac{name} signaling set on
    July 3, 2018 (\numnames{} names) with various compression approaches. The
    representation size in memory is not shown.}
  \begin{tabularx}{\linewidth}{|Xr|}
    \toprule
    \textbf{Representation} & \textbf{Size (MB)} \\
    \midrule
    Plaintext & \plaintextsize \\
    \midrule
    Bloom Filter (0.001\% FP, best-case) & 192 \\
    Bloom Filter (0.01\% FP, best-case) & \bloomlargesize \\
    Bloom Filter (0.1\% FP, best-case) & \bloommedsize \\
    \midrule
    zpaq (method 1, 16 MiB blocks) & \zpaqlargesize \\
    zpaq (method 5, 64 MiB blocks) & \zpaqmedsize \\
    zpaq (method 5, 2048 MiB blocks) & \zpaqsmallsize \\
    \midrule
    DAFSA & \fsalargesize \\
    DAFSA w/ path compaction (PC) & \fsamedsize \\
    DAFSA w/ zpaq (method 5, 64 MiB blocks) & 184 \\
    DAFSA w/ zpaq (method 5, 2048 MiB blocks) & 145 \\
    DAFSA w/ PC, zpaq (method 5, 64 MiB blocks) & 139 \\
    DAFSA w/ PC, zpaq (method 5, 2048 MiB blocks) & 138 \\    
    \bottomrule
  \end{tabularx}
  \label{tab:signaling}
\end{table}

The results are shown in \autoref{tab:signaling}. Bloom filters offer high
compression even with a low false positive rate, and their in-memory
representation is the same as their on-disk representation. However, they still
have false positives, which would leadto those domains becoming inaccessible.
While zpaq in any configuration does not have any false positives or false
negatives and yields excellent compression, its in-memory representation of the
signaling set would simply be the uncompressed set of domains, yielding a memory
requirement of 1.5 GB. My \ac{dafsa}-based representation captures a ``sweet
spot'' between these two alternatives, offering no false positives and, in the
best case, an on-disk representation of just 138 MB with an in-memory
representation of 170 MB.

\subsection{Connection Establishment}
\label{sec:evaluation:performance}

\begin{figure*}[thb]
  \centering
  \subfloat[vs Number of Proofs Requested]{
    \includegraphics[width=0.24\linewidth]{fig/eval_tls_ext/0-time_elapsed_vs_num_proofs_requested}
    \label{fig:evaltlsext:numproof}
  }
  \subfloat[vs Number of Chains Sent]{
    \includegraphics[width=0.24\linewidth]{fig/eval_tls_ext/1-time_elapsed_vs_num_chains_sent}
    \label{fig:evaltlsext:numchain}
  }
  \subfloat[vs Number of Certificates per Chain]{
    \includegraphics[width=0.24\linewidth]{fig/eval_tls_ext/2-time_elapsed_vs_num_certs_per_chain}
    \label{fig:evaltlsext:numcert}
  }
  \subfloat[vs Average Size of Chain]{
    \includegraphics[width=0.24\linewidth]{fig/eval_tls_ext/3-time_elapsed_vs_avg_chain_size}
    \label{fig:evaltlsext:sizechain}
  }
  \caption{Time elapsed during connection establishment.}
  \label{fig:evaltlsext}
\end{figure*}

To measure the performance of connection establishment in \ac{name}, we
implemented the handshake as a custom \ac{tls} extension in the OpenSSL library.
For concrete evaluation of this extension, we use nginx and curl with minor
modifications to use our \ac{tls} extension.

Additionally, we constructed sample sets of domain names based on four parameters:
\begin{inparaenum}
\item the number of proofs requested by the client during the
  ClientHello message (\numlas),
\item the number of certificate chains the domain sends during the ServerHello
  message (\policy),
\item the average number of certificates per chain, and
\item the average size of each certificate chain.
\end{inparaenum}
While varying each of these parameters, we measured the amount of extra data
sent in the \ac{name} handshake, and the latency of the handshake both with and
without the \ac{name} \ac{tls} extension.

We tested this both over the Internet (by connecting to a virtual private server
with latency varying from 30 to 300 ms, referred to as \emph{hophop}), as well
as over the local loopback interface (referred to as \emph{localhost}). The
tests over the internet to \emph{hophop} provide an indication of the effect of
the extension on ``real world'' servers, which are usually accessed over WAN,
whereas the \emph{localhost} tests provide a lower bound on time added due to
sending/receiving/processing extra data. A total of 15385 TLS connections were
established for our testing: 5768 over hophop, 9617 over localhost.

Our results, shown in Figures~\ref{fig:evaltlsext:numproof},
\ref{fig:evaltlsext:numchain}, \ref{fig:evaltlsext:numcert}, and
\ref{fig:evaltlsext:sizechain}, show that in comparison to the mean time
elapsed, there is an approximately 5\% increase in connection establishment
time: an average of 11ms longer for hophop and 1.2ms for localhost. However,
since our \ac{tls} extension does not add any extra round-trips to the
handshake, the time added is small, especially in comparison to random
measurement fluctuations, when we look at confidence intervals within one
standard deviation from the mean (shown as error bars in the figures).

The extra data sent in the \ac{name} handshake is directly dependent on the size
and number of certificate chains, as well as the number of proofs sent. In
particular, the extra data sent from client to server is 1 byte, and the extra
data sent from server to client is
$(2 + (292 \times \text{\#proofs}) +
(\sum_{\text{chain}}\texttt{sizeof}(\text{chain})))$ bytes. While this means
that some connections may result in a great deal of extra data sent, we can
expect that the vast majority of domains will not send additional certificate
chains and the overhead will remain small.